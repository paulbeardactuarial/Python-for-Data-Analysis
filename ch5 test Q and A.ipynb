{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "246e95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Pandas Practice Problems\n",
    "# Based on Chapter 5 of \"Python for Data Analysis\" (3rd Edition)\n",
    "# by Wes McKinney\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "032c7468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple     10\n",
      "orange     8\n",
      "banana    12\n",
      "grape     15\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "apple     25\n",
       "orange    21\n",
       "banana    29\n",
       "grape     35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 1: Series Basics and Operations\n",
    "Create a pandas Series from a dictionary, access elements by label and position,\n",
    "and perform arithmetic operations.\n",
    "\"\"\"\n",
    "\n",
    "def problem_1():\n",
    "    # Create a Series from a dictionary\n",
    "    data_dict = {'apple': 10, 'orange': 8, 'banana': 12, 'grape': 15}\n",
    "    fruits = pd.Series(data_dict)\n",
    "\n",
    "    print(fruits)\n",
    "    fruits.at[\"banana\"]\n",
    "    fruits.iat[0]\n",
    "    fruits.iat[-1]\n",
    "    fruits_2 = fruits * 2\n",
    "    fruits_2 = fruits_2 + 5\n",
    "    \n",
    "    return  fruits_2[fruits_2 > 10]\n",
    "\n",
    "\n",
    "problem_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "382d6e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "price",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inventory",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "value",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "discount_price",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c8b4801b-2d54-4890-a777-7423a86ddbc3",
       "rows": [
        [
         "desktop",
         "desktop",
         "1500",
         "5",
         "4.7",
         "7500",
         "1350.0"
        ],
        [
         "laptop",
         "laptop",
         "1200",
         "10",
         "4.8",
         "12000",
         "1080.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>price</th>\n",
       "      <th>inventory</th>\n",
       "      <th>rating</th>\n",
       "      <th>value</th>\n",
       "      <th>discount_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desktop</th>\n",
       "      <td>desktop</td>\n",
       "      <td>1500</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7500</td>\n",
       "      <td>1350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laptop</th>\n",
       "      <td>laptop</td>\n",
       "      <td>1200</td>\n",
       "      <td>10</td>\n",
       "      <td>4.8</td>\n",
       "      <td>12000</td>\n",
       "      <td>1080.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product  price  inventory  rating  value  discount_price\n",
       "desktop  desktop   1500          5     4.7   7500          1350.0\n",
       "laptop    laptop   1200         10     4.8  12000          1080.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 2: DataFrame Creation and Basic Operations\n",
    "Create a DataFrame from a dictionary of Series, practice basic DataFrame operations\n",
    "and demonstrate understanding of DataFrame structure.\n",
    "\"\"\"\n",
    "\n",
    "def problem_2():\n",
    "    # Sample data about different electronic products\n",
    "    data = {\n",
    "        'product': ['laptop', 'tablet', 'phone', 'desktop', 'smartwatch'],\n",
    "        'price': [1200, 600, 800, 1500, 300],\n",
    "        'inventory': [10, 25, 40, 5, 30],\n",
    "        'rating': [4.8, 4.5, 4.2, 4.7, 3.9]\n",
    "    }\n",
    "    tech_df = pd.DataFrame(data, index=data['product'])\n",
    "    tech_df = tech_df.assign(value = tech_df[\"price\"] * tech_df[\"inventory\"])\n",
    "    tech_df.sort_values(by = [\"price\"], ascending=False, inplace=True)\n",
    "    tech_df = tech_df.assign(discount_price = 0.9 * tech_df['price'])\n",
    "    tech_df = tech_df[tech_df[\"rating\"] > 4.5]\n",
    "    \n",
    "    return  tech_df\n",
    "\n",
    "\n",
    "problem_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f16df21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A    1\n",
       " B    1\n",
       " C    2\n",
       " D    5\n",
       " dtype: int64,\n",
       " None,\n",
       " 0    1.0\n",
       " 1    2.0\n",
       " 2    3.0\n",
       " 3    4.0\n",
       " 4    5.0\n",
       " Name: A, dtype: float64,\n",
       " 0    2.0\n",
       " 1    2.0\n",
       " 2    3.0\n",
       " 3    4.0\n",
       " 4    5.0\n",
       " Name: B, dtype: float64,\n",
       " 0    1.0\n",
       " 1    2.0\n",
       " 2    3.0\n",
       " 3    0.0\n",
       " 4    0.0\n",
       " Name: C, dtype: float64,\n",
       " np.False_]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 3: Handling Missing Data\n",
    "Demonstrate understanding of NaN values in pandas and methods to handle missing data.\n",
    "\"\"\"\n",
    "\n",
    "def problem_3():\n",
    "    # Create a DataFrame with missing values\n",
    "    df = pd.DataFrame({\n",
    "        'A': [1, 2, np.nan, 4, 5],\n",
    "        'B': [np.nan, 2, 3, 4, 5],\n",
    "        'C': [1, 2, 3, np.nan, np.nan],\n",
    "        'D': [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    })\n",
    "    a = df.isna().sum(axis = 0)\n",
    "    b = df.dropna(axis = 1, how = \"all\", inplace=True)\n",
    "    c = df.loc[:, \"A\"] = df.loc[:, \"A\"].fillna(df.loc[:, \"A\"].mean())\n",
    "    d = df.loc[:, \"B\"] = df.loc[:, \"B\"].bfill()\n",
    "    e = df.loc[:, \"C\"] = df.loc[:, \"C\"].fillna(0)\n",
    "    f = df.isna().any().any()\n",
    "   \n",
    "    return  [a, b, c, d, e, f]\n",
    "\n",
    "problem_3()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "98df02d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                     Q1   Q2   Q3   Q4\n",
       " Region Category                       \n",
       " North  Electronics  202  535  960  370\n",
       "        Clothing     206  171  800  120\n",
       "        Food         714  221  566  314\n",
       " South  Electronics  430  558  187  472\n",
       "        Clothing     199  971  763  230,\n",
       "               Q1   Q2   Q3   Q4\n",
       " Category                       \n",
       " Electronics  202  535  960  370\n",
       " Clothing     206  171  800  120\n",
       " Food         714  221  566  314,\n",
       " Region\n",
       " North    535\n",
       " South    558\n",
       " East     513\n",
       " West     660\n",
       " Name: Q2, dtype: int32,\n",
       " Region  Category   \n",
       " North   Electronics    2067\n",
       "         Clothing       1297\n",
       "         Food           1815\n",
       " South   Electronics    1647\n",
       "         Clothing       2163\n",
       "         Food           2481\n",
       " East    Electronics    2494\n",
       "         Clothing       1486\n",
       "         Food           1733\n",
       " West    Electronics    2348\n",
       "         Clothing       2765\n",
       "         Food           2619\n",
       " dtype: int64,\n",
       " 'West',\n",
       "                  Q1      Q2      Q3      Q4\n",
       " Category                                   \n",
       " Clothing     326.50  574.75  599.50  427.00\n",
       " Electronics  544.75  566.50  656.50  371.25\n",
       " Food         692.50  259.75  643.25  566.50]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 4: Hierarchical Indexing\n",
    "Create and manipulate a DataFrame with hierarchical indexing (MultiIndex).\n",
    "\"\"\"\n",
    "\n",
    "def problem_4():\n",
    "    # Create a multi-index DataFrame representing sales data\n",
    "    # Outer index: region (North, South, East, West)\n",
    "    # Inner index: product category (Electronics, Clothing, Food)\n",
    "    # Columns: Q1, Q2, Q3, Q4 (quarterly sales)\n",
    "    \n",
    "    # Sample data structure\n",
    "    index = pd.MultiIndex.from_product([\n",
    "        ['North', 'South', 'East', 'West'],\n",
    "        ['Electronics', 'Clothing', 'Food']\n",
    "    ], names=['Region', 'Category'])\n",
    "    \n",
    "    # Generate some random sales data\n",
    "    np.random.seed(42)  # for reproducibility\n",
    "    sales_data = np.random.randint(100, 1000, size=(12, 4))\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        sales_data,\n",
    "        index=index,\n",
    "        columns=['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    )\n",
    "    \n",
    "    a = df.head(5)\n",
    "    b = df.xs(\"North\", level=\"Region\")\n",
    "    c = df.xs(\"Electronics\", level=\"Category\").loc[:, \"Q2\"]\n",
    "    d = df.sum(axis = 1)\n",
    "    e = df.xs(\"Food\", level = \"Category\").sum(axis=1).idxmax()\n",
    "    f = df.groupby(level='Category').mean()\n",
    "    \n",
    "    return  [a, b, c, d, e, f]\n",
    "\n",
    "problem_4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106895dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sales",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6de6a01f-ae9e-4335-bc9c-906298a0a400",
       "rows": [
        [
         "0",
         "Jan",
         "A",
         "200"
        ],
        [
         "1",
         "Jan",
         "B",
         "120"
        ],
        [
         "2",
         "Jan",
         "C",
         "150"
        ],
        [
         "3",
         "Feb",
         "A",
         "210"
        ],
        [
         "4",
         "Feb",
         "B",
         "140"
        ],
        [
         "5",
         "Feb",
         "C",
         "130"
        ],
        [
         "6",
         "Mar",
         "A",
         "250"
        ],
        [
         "7",
         "Mar",
         "B",
         "160"
        ],
        [
         "8",
         "Mar",
         "C",
         "170"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>product</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>A</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>B</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan</td>\n",
       "      <td>C</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feb</td>\n",
       "      <td>A</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb</td>\n",
       "      <td>B</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feb</td>\n",
       "      <td>C</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mar</td>\n",
       "      <td>A</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mar</td>\n",
       "      <td>B</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mar</td>\n",
       "      <td>C</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month product  sales\n",
       "0   Jan       A    200\n",
       "1   Jan       B    120\n",
       "2   Jan       C    150\n",
       "3   Feb       A    210\n",
       "4   Feb       B    140\n",
       "5   Feb       C    130\n",
       "6   Mar       A    250\n",
       "7   Mar       B    160\n",
       "8   Mar       C    170"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 5: Data Reshaping with pivot_table and melt\n",
    "Transform data between wide and long formats using pivot and melt operations.\n",
    "\"\"\"\n",
    "\n",
    "def problem_5():\n",
    "    # Starting with a \"long format\" dataset of monthly sales by product\n",
    "    data = {\n",
    "        'month': ['Jan', 'Jan', 'Jan', 'Feb', 'Feb', 'Feb', 'Mar', 'Mar', 'Mar'],\n",
    "        'product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "        'sales': [200, 120, 150, 210, 140, 130, 250, 160, 170]\n",
    "    }\n",
    "    df_long = pd.DataFrame(data)\n",
    "    \n",
    "    # TODO: Complete the following tasks\n",
    "    # 1. Convert the long format to wide format with months as columns using pivot_table\n",
    "    # 2. Calculate the total sales for each product across all months\n",
    "    # 3. Calculate the month-over-month percent change in sales for each product\n",
    "    # 4. Convert your wide format table back to long format using melt\n",
    "    # 5. Create a pivot table that shows the sum, mean, and max sales for each product\n",
    "    \n",
    "    return  # Return your transformed DataFrames\n",
    "\n",
    "data = {\n",
    "    'month': ['Jan', 'Jan', 'Jan', 'Feb', 'Feb', 'Feb', 'Mar', 'Mar', 'Mar'],\n",
    "    'product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'sales': [200, 120, 150, 210, 140, 130, 250, 160, 170]\n",
    "}\n",
    "\n",
    "df_long = pd.DataFrame(data)\n",
    "\n",
    "df_long\n",
    "\n",
    "part1 = df_long.pivot_table(\n",
    "    values='sales',\n",
    "    index='product',\n",
    "    columns='month'\n",
    ").reindex(columns=[\"Jan\", \"Feb\", \"Mar\"])\n",
    "\n",
    "part2 = df_long.groupby('product').sum().drop('month', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac6dd9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weekday_mean': 2023-01-01    101.093428\n",
       " 2023-01-08    105.156362\n",
       " 2023-01-15    107.433177\n",
       " 2023-01-22     98.323242\n",
       " 2023-01-29     94.326020\n",
       " 2023-02-05     91.711186\n",
       " Freq: W-SUN, Name: price, dtype: float64,\n",
       " 'daily_change': 2023-01-01         NaN\n",
       " 2023-01-02   -0.001746\n",
       " 2023-01-03    0.013827\n",
       " 2023-01-04    0.030750\n",
       " 2023-01-05   -0.003492\n",
       " 2023-01-06   -0.003504\n",
       " 2023-01-07    0.031115\n",
       " 2023-01-08    0.015140\n",
       " 2023-01-09   -0.007654\n",
       " 2023-01-10    0.010895\n",
       " 2023-01-11   -0.007519\n",
       " 2023-01-12   -0.007619\n",
       " 2023-01-13    0.005392\n",
       " 2023-01-14   -0.034224\n",
       " 2023-01-15   -0.031855\n",
       " 2023-01-16   -0.010064\n",
       " 2023-01-17   -0.019106\n",
       " 2023-01-18    0.007369\n",
       " 2023-01-19   -0.017231\n",
       " 2023-01-20   -0.027838\n",
       " 2023-01-21    0.031859\n",
       " 2023-01-22   -0.003581\n",
       " 2023-01-23    0.002403\n",
       " 2023-01-24   -0.028038\n",
       " 2023-01-25   -0.010374\n",
       " 2023-01-26    0.003412\n",
       " 2023-01-27   -0.023265\n",
       " 2023-01-28    0.009210\n",
       " 2023-01-29   -0.011804\n",
       " 2023-01-30   -0.005243\n",
       " Freq: D, Name: price, dtype: float64,\n",
       " 'rolling_3day_return': 2023-01-01           NaN\n",
       " 2023-01-02           NaN\n",
       " 2023-01-03    101.440868\n",
       " 2023-01-04    102.445235\n",
       " 2023-01-05    102.974194\n",
       " 2023-01-06    103.265454\n",
       " 2023-01-07    103.938987\n",
       " 2023-01-08    104.648495\n",
       " 2023-01-09    105.107118\n",
       " 2023-01-10    105.592528\n",
       " 2023-01-11    105.914515\n",
       " 2023-01-12    106.113550\n",
       " 2023-01-13    106.326881\n",
       " 2023-01-14    106.243553\n",
       " 2023-01-15    105.948013\n",
       " 2023-01-16    105.625380\n",
       " 2023-01-17    105.227429\n",
       " 2023-01-18    104.914167\n",
       " 2023-01-19    104.543562\n",
       " 2023-01-20    104.073787\n",
       " 2023-01-21    103.793099\n",
       " 2023-01-22    103.521950\n",
       " 2023-01-23    103.284598\n",
       " 2023-01-24    102.952463\n",
       " 2023-01-25    102.607348\n",
       " 2023-01-26    102.301160\n",
       " 2023-01-27    101.936096\n",
       " 2023-01-28    101.627516\n",
       " 2023-01-29    101.302242\n",
       " 2023-01-30    100.982541\n",
       " Freq: D, Name: price, dtype: float64,\n",
       " 'high_low': (Timestamp('2023-01-30 00:00:00'),\n",
       "  Timestamp('2023-01-10 00:00:00')),\n",
       " 'cum_returns': 2023-01-01    0.000000\n",
       " 2023-01-02   -0.001746\n",
       " 2023-01-03    0.012057\n",
       " 2023-01-04    0.043177\n",
       " 2023-01-05    0.039534\n",
       " 2023-01-06    0.035891\n",
       " 2023-01-07    0.068123\n",
       " 2023-01-08    0.084295\n",
       " 2023-01-09    0.075996\n",
       " 2023-01-10    0.087719\n",
       " 2023-01-11    0.079540\n",
       " 2023-01-12    0.071315\n",
       " 2023-01-13    0.077091\n",
       " 2023-01-14    0.040229\n",
       " 2023-01-15    0.007093\n",
       " 2023-01-16   -0.003042\n",
       " 2023-01-17   -0.022091\n",
       " 2023-01-18   -0.014884\n",
       " 2023-01-19   -0.031859\n",
       " 2023-01-20   -0.058811\n",
       " 2023-01-21   -0.028826\n",
       " 2023-01-22   -0.032303\n",
       " 2023-01-23   -0.029978\n",
       " 2023-01-24   -0.057175\n",
       " 2023-01-25   -0.066956\n",
       " 2023-01-26   -0.063773\n",
       " 2023-01-27   -0.085554\n",
       " 2023-01-28   -0.077132\n",
       " 2023-01-29   -0.088026\n",
       " 2023-01-30   -0.092808\n",
       " Freq: D, Name: price, dtype: float64,\n",
       " 'weekday_index': 2023-01-02    100.916900\n",
       " 2023-01-03    102.312277\n",
       " 2023-01-04    105.458336\n",
       " 2023-01-05    105.090030\n",
       " 2023-01-06    104.721756\n",
       " 2023-01-09    108.776102\n",
       " 2023-01-10    109.961222\n",
       " 2023-01-11    109.134387\n",
       " 2023-01-12    108.302927\n",
       " 2023-01-13    108.886852\n",
       " 2023-01-16    100.785881\n",
       " 2023-01-17     98.860218\n",
       " 2023-01-18     99.588713\n",
       " 2023-01-19     97.872665\n",
       " 2023-01-20     95.148058\n",
       " 2023-01-23     98.062859\n",
       " 2023-01-24     95.313363\n",
       " 2023-01-25     94.324597\n",
       " 2023-01-26     94.646442\n",
       " 2023-01-27     92.444455\n",
       " 2023-01-30     91.711186\n",
       " Name: price, dtype: float64}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 6: Time Series Manipulation\n",
    "Create and manipulate time series data, resample, and handle time-based operations.\n",
    "\"\"\"\n",
    "\n",
    "def problem_6():\n",
    "    # Create a time series of daily stock prices for 30 days\n",
    "    dates = pd.date_range(start='2023-01-01', periods=30, freq='D')\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate random stock prices with a slight upward trend\n",
    "    initial_price = 100\n",
    "    random_walks = np.random.normal(0.001, 0.02, size=30).cumsum()\n",
    "    prices = initial_price * (1 + random_walks)\n",
    "    \n",
    "    stock_data = pd.Series(prices, index=dates, name='price')\n",
    "    \n",
    "    # TODO: Complete the following tasks\n",
    "    # 1. Resample the daily data to get weekly average prices\n",
    "    # 2. Calculate the daily percentage change in stock price\n",
    "    # 3. Create a 3-day rolling average of the stock price\n",
    "    # 4. Find the date with the highest and lowest stock prices\n",
    "    # 5. Calculate the cumulative return from the start date\n",
    "    # 6. Create a new Series showing only business days (no weekends)\n",
    "    weekday_mean = stock_data.resample( rule = \"W\").mean()\n",
    "    daily_change = stock_data.pct_change()\n",
    "    rolling_3day_return = stock_data.rolling(len(stock_data), min_periods=3).mean()\n",
    "    low, high = stock_data.index[stock_data.argmin()], stock_data.index[stock_data.argmax()]\n",
    "    cum_returns = stock_data / stock_data.iloc[0] - 1\n",
    "    weekday_index = stock_data[stock_data.index.weekday <= 4]\n",
    "\n",
    "    output = {\n",
    "        \"weekday_mean\": weekday_mean,\n",
    "        \"daily_change\": daily_change, \n",
    "        \"rolling_3day_return\": rolling_3day_return, \n",
    "        \"high_low\": (low, high),\n",
    "        \"cum_returns\": cum_returns,\n",
    "        \"weekday_index\": weekday_index\n",
    "    }\n",
    "    \n",
    "    return  output # Return your analyses\n",
    "\n",
    "\n",
    "problem_6()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828899dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 7: Data Cleaning and String Operations\n",
    "Clean messy data and use pandas string methods for text processing.\n",
    "\"\"\"\n",
    "\n",
    "def problem_7():\n",
    "    # Dataset with messy string data\n",
    "    data = {\n",
    "        'customer_id': ['A001', 'A002', 'A003', 'A004', 'A005'],\n",
    "        'name': ['John Smith', ' JANE DOE', 'Bob  Johnson', 'Alice Brown  ', '  David Lee'],\n",
    "        'email': ['john.smith@example.com', 'jane.doe@example.com', 'bob@example', 'alice@wrong@format.com', 'david@example.com'],\n",
    "        'phone': ['(555) 123-4567', '555.987.6543', '5551112222', '555-333-4444', 'NA'],\n",
    "        'purchase_date': ['2023-01-15', '01/30/2023', '2023-02-15', '20230302', '2023.03.15']\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # TODO: Complete the following tasks\n",
    "    # 1. Standardize all names (proper case, no extra spaces)\n",
    "    # 2. Extract the domain from each email address\n",
    "    # 3. Create a boolean column indicating if the email is valid (contains @ and a domain)\n",
    "    # 4. Clean and standardize phone numbers to format: XXX-XXX-XXXX\n",
    "    # 5. Convert all dates to datetime objects with a consistent format\n",
    "    # 6. Create a new column with the number of days since purchase (from today)\n",
    "    \n",
    "    return  # Return your cleaned DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 8: Group Operations with groupby\n",
    "Demonstrate understanding of the split-apply-combine pattern with groupby.\n",
    "\"\"\"\n",
    "\n",
    "def problem_8():\n",
    "    # Sales data by category, store, and date\n",
    "    data = {\n",
    "        'date': pd.date_range(start='2023-01-01', periods=20, freq='D').repeat(3),\n",
    "        'store': ['Store_A', 'Store_B', 'Store_C'] * 20,\n",
    "        'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Home'], size=60),\n",
    "        'sales': np.random.randint(500, 5000, size=60),\n",
    "        'units': np.random.randint(1, 50, size=60)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # TODO: Complete the following tasks\n",
    "    # 1. Calculate the total sales and units sold by store\n",
    "    # 2. Find the best-selling category (by sales) in each store\n",
    "    # 3. Calculate the average daily sales for each store-category combination\n",
    "    # 4. Find the day of the week with the highest average sales\n",
    "    # 5. Create a pivot table showing total sales by store (rows) and category (columns)\n",
    "    # 6. Calculate the cumulative sales over time for each store\n",
    "    \n",
    "    return  # Return your analyses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a335b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 9: Merging and Joining DataFrames\n",
    "Combine multiple DataFrames using different join types.\n",
    "\"\"\"\n",
    "\n",
    "def problem_9():\n",
    "    # Products DataFrame\n",
    "    products = pd.DataFrame({\n",
    "        'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "        'product_name': ['Laptop', 'Tablet', 'Phone', 'Desktop', 'Printer'],\n",
    "        'category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics'],\n",
    "        'price': [1200, 600, 800, 1500, 300]\n",
    "    })\n",
    "    \n",
    "    # Sales DataFrame\n",
    "    sales = pd.DataFrame({\n",
    "        'sale_id': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007'],\n",
    "        'product_id': ['P001', 'P002', 'P003', 'P001', 'P005', 'P006', 'P007'],\n",
    "        'quantity': [3, 5, 2, 1, 4, 2, 1],\n",
    "        'sale_date': pd.date_range(start='2023-01-01', periods=7, freq='D')\n",
    "    })\n",
    "    \n",
    "    # Customers DataFrame\n",
    "    customers = pd.DataFrame({\n",
    "        'customer_id': ['C001', 'C002', 'C003', 'C004'],\n",
    "        'name': ['John Smith', 'Jane Doe', 'Bob Johnson', 'Alice Brown'],\n",
    "        'membership': ['Gold', 'Silver', 'Bronze', 'Gold']\n",
    "    })\n",
    "    \n",
    "    # Customer purchases DataFrame\n",
    "    purchases = pd.DataFrame({\n",
    "        'sale_id': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007'],\n",
    "        'customer_id': ['C001', 'C002', 'C001', 'C003', 'C002', 'C005', 'C006']\n",
    "    })\n",
    "    \n",
    "    # TODO: Complete the following tasks\n",
    "    # 1. Merge the sales and products DataFrames to get product details for each sale\n",
    "    # 2. Calculate the total revenue for each product (price * quantity)\n",
    "    # 3. Merge the sales data with customer information\n",
    "    # 4. Find which products have no sales\n",
    "    # 5. Find customers who have not made any purchases\n",
    "    # 6. Create a summary of total spending by customer membership type\n",
    "    \n",
    "    return  # Return your merged DataFrames and analyses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem 10: Advanced Pandas Features\n",
    "Use advanced features like categorical data, custom aggregations, and window functions.\n",
    "\"\"\"\n",
    "\n",
    "def problem_10():\n",
    "    # Create a dataset of student exam scores\n",
    "    np.random.seed(42)\n",
    "    n_students = 1000\n",
    "    \n",
    "    # Generate student data\n",
    "    student_ids = [f'S{i:04d}' for i in range(1, n_students+1)]\n",
    "    grades = ['A', 'B', 'C', 'D', 'F']\n",
    "    grade_weights = [0.15, 0.35, 0.30, 0.15, 0.05]  # Probability distribution\n",
    "    \n",
    "    data = {\n",
    "        'student_id': student_ids,\n",
    "        'gender': np.random.choice(['M', 'F'], size=n_students),\n",
    "        'year': np.random.choice([1, 2, 3, 4], size=n_students),\n",
    "        'major': np.random.choice(['CS', 'Eng', 'Math', 'Phys', 'Chem', 'Bio'], size=n_students),\n",
    "        'exam1': np.random.randint(50, 101, size=n_students),\n",
    "        'exam2': np.random.randint(50, 101, size=n_students),\n",
    "        'final_exam': np.random.randint(50, 101, size=n_students),\n",
    "        'grade': np.random.choice(grades, size=n_students, p=grade_weights)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # TODO: Complete the following tasks\n",
    "    # 1. Convert 'grade' and 'major' columns to categorical data type\n",
    "    # 2. Calculate the average score for each exam (exam1, exam2, final_exam)\n",
    "    # 3. Create a new column 'overall_score' which is a weighted average: \n",
    "    #    20% exam1, 30% exam2, 50% final_exam\n",
    "    # 4. Rank students based on their overall score (1 being the highest)\n",
    "    # 5. Group students by major and year, and calculate:\n",
    "    #    - Average overall score\n",
    "    #    - Percentage of students with each grade\n",
    "    #    - Number of students\n",
    "    # 6. Identify students who improved the most from exam1 to final_exam\n",
    "    \n",
    "    return  # Return your analyses\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Uncomment the problem you want to work on\n",
    "    # problem_1()\n",
    "    # problem_2()\n",
    "    # problem_3()\n",
    "    # problem_4()\n",
    "    # problem_5()\n",
    "    # problem_6()\n",
    "    # problem_7()\n",
    "    # problem_8()\n",
    "    # problem_9()\n",
    "    # problem_10()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
